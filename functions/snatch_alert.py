import os
import requests
import json
from datetime import datetime, timedelta
import random
import time
from bs4 import BeautifulSoup

# ===================================================
# Ù…ØªØºÙŠØ±Ø© Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø³Ø±ÙŠØ© ÙˆØ§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
# ===================================================
# Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ„Ø¬Ø±Ø§Ù…
TELEGRAM_TOKEN = "8377697278:AAEptchGlYa19eg3g9bi-iKtU3-GflVBaJA"
TELEGRAM_CHAT_ID = "1554251396"

# Ù…Ø¯ÙŠØ± Ù…ÙØ§ØªÙŠØ­ API Ø§Ù„Ø¯ÙˆØ§Ø±Ø© (Ø³Ø¹Ø© 600 Ø·Ù„Ø¨ ÙŠÙˆÙ…ÙŠØ§Ù‹)
WHOIS_API_KEYS_POOL = [
    {"provider": "WHOISFREAKS", "key": "8a415a6c9b274ad7896f44755479ea99", "url": "[https://api.whoisfreaks.com/v1.0/whois?apiKey=](https://api.whoisfreaks.com/v1.0/whois?apiKey=){key}&domainName={domain}"},
    {"provider": "WHOISXML", "key": "At_U9un5tTeNXMErhyGJoSwsTnuZ0T8s", "url": "[https://www.whoisxmlapi.com/whois/api/v2?apiKey=](https://www.whoisxmlapi.com/whois/api/v2?apiKey=){key}&domainName={domain}"},
]

# Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø­Ù…Ø§ÙŠØ© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
]
CURRENT_MARKET_TRENDS = ['ai', 'crypto', 'nft', 'invest', 'meta', 'web3', 'fintech']
EXPLOIT_KEYWORDS = ['bank', 'loan', 'cash', 'money', 'trade', 'secure', 'password']


# ===================================================
# Ø¯ÙˆØ§Ù„ ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ø­Ù…Ø§ÙŠØ© ÙˆØ§Ù„ØªÙ‡ÙŠØ¦Ø©
# ===================================================

def get_random_headers():
    return {'User-Agent': random.choice(USER_AGENTS)}

def get_active_proxies(max_proxies=50):
    """ÙŠØªÙ… Ù…Ø­Ø§ÙƒØ§Ø© Ø¬Ù„Ø¨ ÙˆØ§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø±ÙˆÙƒØ³ÙŠØ§Øª."""
    # Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯ Ø¹Ù„Ù‰ Netlify Ø¨Ø³Ø±Ø¹Ø©ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ù‡Ù†Ø§ Ù‚Ø§Ø¦Ù…Ø© ÙˆÙ‡Ù…ÙŠØ© (ÙŠÙØªØ±Ø¶ Ø£Ù† Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ ÙŠØ¬Ù„Ø¨Ù‡Ø§)
    # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙˆÙ‡Ù…ÙŠØ© (ÙŠØ¬Ø¨ Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø¨ÙƒÙˆØ¯ Ø¬Ù„Ø¨ Ø­Ù‚ÙŠÙ‚ÙŠ):
    return ['[http://1.2.3.4:8080](http://1.2.3.4:8080)', '[http://5.6.7.8:8080](http://5.6.7.8:8080)'] if not os.environ.get('NETLIFY') else []

def get_random_proxy(active_proxies):
    if active_proxies:
        proxy_url = random.choice(active_proxies)
        return {'http': proxy_url, 'https': proxy_url}
    return {}

# ===================================================
# Ø¯ÙˆØ§Ù„ ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ø¬Ù†ÙŠ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„
# ===================================================

def scrape_domains(active_proxies):
    """Ø¬Ù†ÙŠ Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø¯ÙˆÙ…ÙŠÙ†Ø§Øª Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…ØªØ¹Ø¯Ø¯Ø©."""
    # Ø¯Ù…Ø¬ Ù…ØµØ§Ø¯Ø± Ø¬Ù†ÙŠ Ù…ØªØ¹Ø¯Ø¯Ø© (Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…ÙƒØªØ´ÙØ© ÙÙŠ Ù…Ù†ØªØ¯ÙŠØ§Øª Ø§Ù„Ù‚Ø¨Ø¹Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡)
    target_urls = [
        "[https://www.expireddomains.net/deleted-com-domains/](https://www.expireddomains.net/deleted-com-domains/)", # Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        # "[http://dropped-domains-source-2.com](http://dropped-domains-source-2.com)", # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù‡Ù†Ø§
    ]
    all_raw_domains = []
    
    for url in target_urls:
        proxy_config = get_random_proxy(active_proxies)
        headers = get_random_headers()
        try:
            # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø¬Ù†ÙŠ (Ø³Ù†ÙØªØ±Ø¶ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ 1000 Ø¯ÙˆÙ…ÙŠÙ† Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±)
            for i in range(1000):
                domain_name = f"testdomain{i}-{random.randint(1, 99)}.{random.choice(['com', 'ai', 'io', 'net', 'xyz'])}"
                # Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ…Ø© InitialAge Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù„Ù„Ù…Ø­Ø§ÙƒØ§Ø©
                all_raw_domains.append({'Domain': domain_name, 'InitialAge': random.randint(1, 25)}) 
        except Exception:
            pass
            
    return all_raw_domains

def fetch_precise_whois(domain_name, active_proxies):
    """Ù…Ø¯ÙŠØ± Ù…ÙØ§ØªÙŠØ­ API Ø§Ù„Ø¯ÙˆØ§Ø±Ø© ÙŠØ¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª WHOIS."""
    
    # Ø§Ø®ØªÙŠØ§Ø± Ù…ÙØªØ§Ø­ API Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù„Ù„ØªØ¨Ø¯ÙŠÙ„ ÙˆØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ø¯ÙˆØ¯
    api_source = random.choice(WHOIS_API_KEYS_POOL)
    
    # Ø¨Ù†Ø§Ø¡ URL Ø§Ù„Ø·Ù„Ø¨ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø²ÙˆØ¯ (WhoisXML Ø£Ùˆ WhoisFreaks)
    url = api_source['url'].format(key=api_source['key'], domain=domain_name)
    
    try:
        response = requests.get(url, headers=get_random_headers(), proxies=get_random_proxy(active_proxies), timeout=10)
        response.raise_for_status()
        data = response.json()
        
        # ØªÙˆØ­ÙŠØ¯ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if api_source['provider'] == "WHOISXML":
            creation_date = data.get('createdDate')
            domain_status = data.get('status')
            nameservers = data.get('nameServers')
        else: # WHOISFREAKS
            creation_date = data.get('registrant_details', {}).get('creation_date')
            domain_status = data.get('domain_details', {}).get('status')
            nameservers = data.get('domain_details', {}).get('nameservers', [])

        return {
            'creation_year': int(creation_date[:4]) if creation_date and len(creation_date) >= 4 else 0,
            'status': domain_status,
            'is_premium': data.get('premium', False),
            'nameservers': nameservers
        }
    except Exception as e:
        return {'creation_year': 0, 'status': 'Unknown', 'is_premium': False, 'nameservers': []}


# ===================================================
# ÙˆØ­Ø¯Ø§Øª Ù…Ø¤Ø´Ø± Ø§Ù„Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø·Ù„Ù‚Ø© (ASI) ÙˆØ§Ù„Ù‚Ø¨Ø¹Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡
# ===================================================

def calculate_inherited_score(precise_whois_data):
    """Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ù…ÙˆØ±ÙˆØ«Ø© (Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù‚Ø¨Ø¹Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡)"""
    score = 0
    nameservers = precise_whois_data.get('nameservers', [])
    
    # Ø§Ù„Ù…Ø¤Ø´Ø± 1: Ø¨ØµÙ…Ø© Ø§Ù„Ø§Ø³ØªØ¶Ø§ÙØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Legacy Hosting Footprint) - 15 Ù†Ù‚Ø·Ø©
    if nameservers and len(nameservers) > 1 and not any('default' in ns or 'parking' in ns for ns in nameservers):
        score += 15
        
    # Ø§Ù„Ù…Ø¤Ø´Ø± 2: Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ù…ÙˆØ±ÙˆØ«Ø© Ø§Ù„Ù…ÙØ­Ø³Ù‘Ù†Ø© (Inherited Authority) - 15 Ù†Ù‚Ø·Ø©
    if any(kw in str(nameservers).lower() for kw in ['corp', 'ltd', 'inc', 'solutions']):
        score += 15
        
    return score

def check_domain_uniqueness(domain_name):
    """ÙˆØ­Ø¯Ø© Ø§Ù„ØªÙØ±Ù‘ÙØ¯: Ù‡Ù„ ÙŠÙ†Ø§ÙØ³ Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙˆÙ…ÙŠÙ† Ø£Ø³Ù…Ø§Ø¡ Ù…Ø´Ø§Ø¨Ù‡Ø©ØŸ"""
    domain_part = domain_name.split('.')[0]
    if len(domain_part) < 6:
        return "Ø¹Ø§Ù„ÙŠ"
    if domain_part.endswith(('pro', 'hub', 'ai')):
        return "Ù…ØªÙˆØ³Ø·"
    return "Ù…Ù†Ø®ÙØ¶"


def calculate_asi(domain_entry, precise_whois_data):
    """ÙŠØ­Ø³Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø·Ù„Ù‚Ø© (ASI) Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ."""
    asi_score = 0
    domain_name = domain_entry['Domain'].lower()
    domain_part = domain_name.split('.')[0]
    
    creation_year = precise_whois_data.get('creation_year', 0)
    domain_age = datetime.now().year - creation_year if creation_year > 0 else 0
    
    # I. Ø§Ù„Ù†Ø¯Ø±Ø© Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© (40 Ù†Ù‚Ø·Ø©)
    if domain_age >= 20: asi_score += 25
    elif domain_age >= 10: asi_score += 15
    length = len(domain_part)
    if length <= 4: asi_score += 15
    
    # II. Ø§Ù„Ø§Ø³ØªØºÙ„Ø§Ù„ Ø§Ù„Ù…Ø§Ù„ÙŠ (40 Ù†Ù‚Ø·Ø©)
    if any(kw in domain_part for kw in EXPLOIT_KEYWORDS): asi_score += 20
    if precise_whois_data.get('is_premium', False): asi_score += 15
        
    # III. Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø³ÙˆÙ‚ ÙˆØ§Ù„Ù‚Ø¨Ø¹Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡ (45 Ù†Ù‚Ø·Ø©)
    if any(trend in domain_part for trend in CURRENT_MARKET_TRENDS): asi_score += 15
    if any(kw in domain_part for kw in ['cbd', 'gambling']): asi_score += 20
    if not ('-' in domain_part or any(c.isdigit() for c in domain_part)): asi_score += 10
        
    # IV. Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ù…ÙˆØ±ÙˆØ«Ø© (30 Ù†Ù‚Ø·Ø©)
    asi_score += calculate_inherited_score(precise_whois_data)
    
    # V. Ø§Ù„Ù…Ø¶Ø§Ø¹Ù
    tld = domain_name.split('.')[-1]
    tld_multipliers = {'com': 1.25, 'ai': 1.30, 'io': 1.20, 'net': 1.10}
    multiplier = tld_multipliers.get(tld, 1.0)
    
    return asi_score * multiplier, domain_age

def evaluate_acquisition_risk(precise_whois_data):
    """ØªÙ‚ÙŠÙŠÙ… Ù…Ø®Ø§Ø·Ø± "Ø§Ù„ØªÙ‡Ø±Ø¨ Ù…Ù† Ø§Ù„ØªØ¬Ø¯ÙŠØ¯"."""
    status = precise_whois_data.get('status', '').lower()
    if 'redemptionperiod' in status or 'pendingdelete' in status:
        return "Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ù‚ØªÙ†Ø§Øµ"
    if 'clienthold' in status or 'transferlock' in status:
        return "ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„Ø­Ø°Ø±"
    return "Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ù‚ØªÙ†Ø§Øµ"


def apply_asi_filter(all_raw_domains, active_proxies):
    """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ±Ø´ÙŠØ­ Ø§Ù„Ù…Ø³Ø¨Ù‚ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚ ASI."""
    
    # === Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„ØªØ±Ø´ÙŠØ­ Ø§Ù„Ù…Ø³Ø¨Ù‚ Ø§Ù„Ù‚Ø§Ø³ÙŠ (Ù„ØªÙ‚Ù„ÙŠØµ 1000+ Ø¥Ù„Ù‰ 600) ===
    pre_filtered_list = []
    for entry in all_raw_domains:
        domain_name = entry['Domain'].lower()
        domain_part = domain_name.split('.')[0]
        tld = domain_name.split('.')[-1]
        
        # Ø´Ø±ÙˆØ· Ø§Ù„ØªØ±Ø´ÙŠØ­ Ø§Ù„ØµØ§Ø±Ù…Ø©
        if len(domain_part) > 10 or tld not in ['com', 'ai', 'io', 'net']:
            continue
        try:
            if int(entry.get('InitialAge', 0)) < 5:
                continue
        except ValueError:
            continue
        pre_filtered_list.append(entry)
        
    # Ù†Ø®ØªØ§Ø± 550 Ø¯ÙˆÙ…ÙŠÙ† ÙÙ‚Ø· Ù„ØªØ­Ù„ÙŠÙ„ WHOIS API (Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù€ 600 Ø·Ù„Ø¨)
    processing_list = pre_filtered_list[:550]

    # === Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: ØªØ­Ù„ÙŠÙ„ ASI Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆÙˆØ­Ø¯Ø© Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø­Ø§Ø³Ù… ===
    final_results = []
    
    for entry in processing_list:
        precise_data = fetch_precise_whois(entry['Domain'], active_proxies)
        asi_score, domain_age = calculate_asi(entry, precise_data)
        
        final_results.append({
            'Domain': entry['Domain'],
            'ASI_Score': asi_score,
            'Age': domain_age,
            'Uniqueness': check_domain_uniqueness(entry['Domain']),
            'Risk': evaluate_acquisition_risk(precise_data),
        })
        
        time.sleep(random.uniform(0.1, 0.3)) 

    final_results.sort(key=lambda x: x['ASI_Score'], reverse=True)
    return final_results[:3]

def format_final_alert(targets):
    """ØªÙ†Ø³ÙŠÙ‚ Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªÙ„Ø¬Ø±Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù…Ø¹ ÙˆØ­Ø¯Ø© Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø­Ø§Ø³Ù…."""
    message = "ğŸ‘‘ *Ø¥Ù†Ø°Ø§Ø± Ø§Ù‚ØªÙ†Ø§Øµ Ø§Ù„Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø·Ù„Ù‚Ø© (Apex Snatch Alert)* ğŸ‘‘\n\n"
    message += f"â° *Ø§Ù„ØªÙˆÙ‚ÙŠØª:* {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
    message += "--------------------------------------\n"
    
    for i, target in enumerate(targets):
        estimated_sale_price = 1500 + (target['ASI_Score'] * 20) 
        
        # Ù…Ø¤Ø´Ø± Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        if target['Uniqueness'] == 'Ø¹Ø§Ù„ÙŠ' and target['Risk'] == 'Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ù‚ØªÙ†Ø§Øµ':
            decision_text = "**ğŸ¥‡ Ø§Ù„Ø§Ù‚ØªÙ†Ø§Ø¡ Ø±Ù‚Ù… {}: ÙØ±ØµØ© Ø°Ù‡Ø¨ÙŠØ© Ø¨Ù„Ø§ Ù…Ù†Ø§ÙØ³Ø©**".format(i+1)
        elif target['Risk'] == 'Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ù‚ØªÙ†Ø§Øµ':
            decision_text = "**ğŸ¥ˆ ØªÙˆØµÙŠØ© Ù‚ÙˆÙŠØ©: Ø§Ù‚ØªÙ†Ø§Øµ Ù…Ø¶Ù…ÙˆÙ†ØŒ Ù…Ø®Ø§Ø·Ø± Ø¹ÙˆØ¯Ø© Ø§Ù„Ù…Ø§Ù„Ùƒ Ù…Ù†Ø®ÙØ¶Ø©**"
        else:
            decision_text = "âŒ ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„Ø­Ø°Ø±: Ø¯ÙˆÙ…ÙŠÙ† Ø¹Ø§Ù„ÙŠ Ø§Ù„Ù‚ÙŠÙ…Ø©ØŒ Ù„ÙƒÙ† Ù‚Ø¯ ÙŠØ¹ÙˆØ¯ Ø§Ù„Ù…Ø§Ù„Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ"
        
        message += (
            f"ğŸš€ *Ø§Ù„Ù‡Ø¯Ù Ø±Ù‚Ù… {i+1}:* `{target['Domain']}`\n"
            f"   - *Ù…Ø¤Ø´Ø± ASI:* **{target['ASI_Score']:.1f}**\n"
            f"   - *Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:* **{estimated_sale_price:.0f}$ ÙÙ…Ø§ ÙÙˆÙ‚**\n"
            f"   - *Ø§Ù„Ø¹Ù…Ø±/Ø§Ù„ØªÙØ±Ù‘ÙØ¯:* {target['Age']} Ø³Ù†Ø© / ØªÙØ±Ù‘ÙØ¯ **{target['Uniqueness']}**\n"
            f"   - *Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø´Ø±Ø§Ø¡:* {target['Risk']}\n"
            f"{decision_text}\n"
            f"--------------------------------------\n"
        )
        
    message += "â³ *Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ù‚ØªÙ†Ø§Øµ Ø§Ù„ÙÙˆØ±ÙŠ - Ø§Ø³ØªØ¹Ù…Ù„ Ø®Ø¯Ù…Ø© Backordering* ğŸš¨"
    return message


def send_telegram_alert(text, token, chat_id):
    """ØªØ±Ø³Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ Ø¨ÙˆØª ØªÙ„Ø¬Ø±Ø§Ù…."""
    url = f"[https://api.telegram.org/bot](https://api.telegram.org/bot){token}/sendMessage"
    payload = {'chat_id': chat_id, 'text': text, 'parse_mode': 'Markdown'}
    try:
        requests.post(url, data=payload).raise_for_status()
    except Exception as e:
        print(f"ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© ØªÙ„Ø¬Ø±Ø§Ù…: {e}")

# ===================================================
# Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„ØªÙŠ ØªØ¹Ù…Ù„ Ø¹Ø¨Ø± Netlify
# ===================================================

def handler(event, context):
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªØ´ØºÙŠÙ„ Netlify Cron Job."""
    
    active_proxies = get_active_proxies() 
    
    all_dropped_domains = scrape_domains(active_proxies) 
    
    if not all_dropped_domains:
        send_telegram_alert("âŒ ÙØ´Ù„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¬Ù†ÙŠ. Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø©.", TELEGRAM_TOKEN, TELEGRAM_CHAT_ID)
        return {"statusCode": 500}
        
    top_3_targets = apply_asi_filter(all_dropped_domains, active_proxies)
    
    final_message = format_final_alert(top_3_targets)
    send_telegram_alert(final_message, TELEGRAM_TOKEN, TELEGRAM_CHAT_ID)
    
    return {"statusCode": 200, "body": "ØªÙ…Øª Ø¹Ù…Ù„ÙŠØ© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯ÙˆÙ…ÙŠÙ†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­"}
